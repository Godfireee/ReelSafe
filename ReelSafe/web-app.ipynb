{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2721,"status":"ok","timestamp":1714399804147,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"},"user_tz":-330},"id":"38nZy8lQ2BXc","outputId":"73f64313-869e-4cff-e9dd-141b01eb4c92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install moviepy\n","!pip install git+https://github.com/openai/whisper.git"],"metadata":{"id":"2KFsISqR4hdL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714399816350,"user_tz":-330,"elapsed":12205,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"5d8e7648-ac34-48b0-c16d-9af2084b149e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.2)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.1)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (10.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-51uclz5o\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-51uclz5o\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.59.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0+cpu)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n","Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper==20231117) (8.10.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.6.0)\n","Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.4)\n","Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.42.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.4.16)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"elapsed":1483,"status":"ok","timestamp":1714399817831,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"},"user_tz":-330},"id":"YagGNKnC2NlG","outputId":"d8583c44-fa2f-4f9e-acfe-78943ac2663c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n","                ('logisticregression',\n","                 LogisticRegression(class_weight='balanced', n_jobs=-1))])"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n","                (&#x27;logisticregression&#x27;,\n","                 LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n","                (&#x27;logisticregression&#x27;,\n","                 LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=-1)</pre></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":3}],"source":["import joblib\n","hate_speech_model_path = '/content/drive/MyDrive/insta-reel/lr_pipeline.joblib'\n","hate_speech_model = joblib.load(hate_speech_model_path)\n","hate_speech_model"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"PM9IA8_u2bM_","executionInfo":{"status":"ok","timestamp":1714399817831,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"outputs":[],"source":["import numpy as np\n","def predict_hate_speech(text):\n","    pred = hate_speech_model.predict([text])[0]\n","    prob = round(np.max(hate_speech_model.predict_proba([text])[0]),2)\n","    return pred,prob"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1714399817831,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"},"user_tz":-330},"id":"PDPLpYIi2mf8","outputId":"412a5838-4a72-400b-e23e-ab4c95e0fd9b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('neither', 0.49)"]},"metadata":{},"execution_count":5}],"source":["text = 'i am very angry'\n","pred,prob = predict_hate_speech(text)\n","pred,prob"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32672,"status":"ok","timestamp":1714399850500,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"},"user_tz":-330},"id":"prs117OS5TAr","outputId":"2126a572-0b43-443d-d00e-89489f8142a6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.engine.sequential.Sequential at 0x7c3c652cf490>"]},"metadata":{},"execution_count":6}],"source":["import tensorflow as tf\n","cls_model_path = '/content/drive/MyDrive/insta-reel/xception_checkpoint.keras'\n","cls_model = tf.keras.models.load_model(cls_model_path)\n","cls_model"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"if2Uucfr39lW","executionInfo":{"status":"ok","timestamp":1714399850500,"user_tz":-330,"elapsed":10,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"outputs":[],"source":["from PIL import Image\n","cls_label = {'not_smoking': 0, 'smoking': 1}\n","label = list(cls_label.keys())\n","\n","def predict_smoking(img_path):\n","    img = Image.open(img_path)\n","    resized_img = img.resize((299, 299))\n","    img = np.asarray(resized_img)\n","    img = np.expand_dims(img, axis=0)\n","    img = img / 255\n","    predictions = cls_model.predict(img)\n","    return label[np.argmax(predictions)],round(np.max(predictions),2)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"FYRWD9O_5tEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714399851926,"user_tz":-330,"elapsed":1435,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"8e41f61a-8fbf-45f5-e3d1-063f4707a7f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 877ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["('smoking', 0.95)"]},"metadata":{},"execution_count":8}],"source":["img_path = '/content/drive/MyDrive/insta-reel/sample_vid_data/images.jpeg'\n","pred,prob = predict_smoking(img_path)\n","pred,prob"]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tqdm import tqdm\n","\n","def predict_smoking_video_1(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = 0\n","    predictions_dict = {}\n","\n","    # Get total number of frames\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Set the frame skip interval\n","    frame_skip_interval = 30  # Change this value as needed for performance\n","\n","    # tqdm progress bar\n","    pbar = tqdm(total=total_frames)\n","    pred = 'not smoking'\n","    predictions = 1\n","    while True:\n","        # Read the frame\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # Only process every nth frame\n","        if frame_count % frame_skip_interval == 0:\n","            resized_img = cv2.resize(frame, (299, 299))\n","            img = np.asarray(resized_img)\n","            img = np.expand_dims(img, axis=0)\n","            # print(img.shape)\n","\n","            img = img / 255\n","            predictions = cls_model.predict(img)\n","\n","            if np.argmax(predictions) == 1:\n","                if np.max(predictions) >= 0.9:\n","                    pred = 'smoking'\n","                    break\n","\n","        frame_count += 1\n","        pbar.update(1)\n","\n","    return pred, round(np.max(predictions), 2)\n"],"metadata":{"id":"EZ7s_etd4xi_","executionInfo":{"status":"ok","timestamp":1714399853337,"user_tz":-330,"elapsed":1413,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tqdm import tqdm\n","\n","def predict_smoking_video_2(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = 0\n","    predictions_dict = {}\n","\n","    # Get total number of frames\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Calculate the interval between frames to select 20 frames\n","    interval = total_frames // 30\n","    selected_frames = [i * interval for i in range(20)]\n","\n","    # tqdm progress bar\n","    pbar = tqdm(total=20)\n","    pred = 'not smoking'\n","    predictions = 1\n","    while frame_count < total_frames:\n","        ret = cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n","        if not ret:\n","            break\n","\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        if frame_count in selected_frames:\n","            resized_img = cv2.resize(frame, (299, 299))\n","            img = np.asarray(resized_img)\n","            img = np.expand_dims(img, axis=0)\n","\n","            img = img / 255\n","            predictions = cls_model.predict(img)\n","\n","            if np.argmax(predictions) == 1 and np.max(predictions) >= 0.9:\n","                pred = 'smoking'\n","                break\n","\n","            pbar.update(1)\n","\n","        frame_count += 1\n","\n","    return pred, round(np.max(predictions), 2)"],"metadata":{"id":"0vgCcb2uPiNH","executionInfo":{"status":"ok","timestamp":1714399853337,"user_tz":-330,"elapsed":4,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tqdm import tqdm\n","\n","def predict_smoking_video_1(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = 0\n","    predictions_dict = {}\n","\n","    # Get total number of frames\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Get frames per second (FPS)\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    # Calculate the number of frames to skip to have one frame per second\n","    frames_to_skip = int(round(fps))\n","\n","    # tqdm progress bar\n","    pbar = tqdm(total=total_frames)\n","    pred = 'not smoking'\n","    predictions = 1\n","    while True:\n","        # Skip frames until one frame per second\n","        for _ in range(frames_to_skip):\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            frame_count += 1\n","            pbar.update(1)\n","\n","        if not ret:\n","            break\n","\n","        resized_img = cv2.resize(frame, (299, 299))\n","        img = np.asarray(resized_img)\n","        img = np.expand_dims(img, axis=0)\n","        # print(img.shape)\n","\n","        img = img / 255\n","        predictions = cls_model.predict(img)\n","\n","        if np.argmax(predictions) == 1:\n","            if np.max(predictions) >= 0.9:\n","                pred = 'smoking'\n","                break\n","\n","    return pred, round(np.max(predictions), 2)\n"],"metadata":{"id":"-oCY1hswfOAa","executionInfo":{"status":"ok","timestamp":1714399853337,"user_tz":-330,"elapsed":3,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tqdm import tqdm\n","from concurrent.futures import ThreadPoolExecutor\n","\n","def predict_frame(frame, cls_model):\n","    resized_img = cv2.resize(frame, (299, 299))\n","    img = np.asarray(resized_img)\n","    img = np.expand_dims(img, axis=0)\n","    img = img / 255\n","    predictions = cls_model.predict(img)\n","    return predictions\n","\n","def predict_smoking_video_3(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = 0\n","\n","    # Get total number of frames\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Calculate the interval between frames to select 20 frames\n","    interval = total_frames // 30\n","    selected_frames = [i * interval for i in range(20)]\n","\n","    predictions_dict = {}\n","\n","    # tqdm progress bar\n","    pbar = tqdm(total=20)\n","\n","    pred = 'not smoking'\n","    predictions = []\n","\n","    # Function to process each frame\n","    def process_frame(frame):\n","        predictions.append(predict_frame(frame, cls_model))\n","        pbar.update(1)\n","\n","    with ThreadPoolExecutor() as executor:\n","        while frame_count < total_frames:\n","            ret = cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n","            if not ret:\n","                break\n","\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","\n","            if frame_count in selected_frames:\n","                executor.submit(process_frame, frame)\n","\n","            frame_count += 1\n","\n","    for prediction in predictions:\n","        if np.argmax(prediction) == 1 and np.max(prediction) >= 0.9:\n","            pred = 'smoking'\n","            break\n","\n","    return pred, round(np.max(predictions), 2)\n"],"metadata":{"id":"lCMruzesVJQC","executionInfo":{"status":"ok","timestamp":1714399853337,"user_tz":-330,"elapsed":3,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["video_path = '/content/drive/MyDrive/insta-reel/sample_vid_data/sample_smoking.mp4'\n","pred,prob = predict_smoking_video_2(video_path)\n","pred,prob"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_kVHyZ6xHAC","executionInfo":{"status":"ok","timestamp":1714399853916,"user_tz":-330,"elapsed":583,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"500a948a-0980-4c3c-b55d-1fa601d1362a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 96ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["('smoking', 0.92)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["video_path = '/content/drive/MyDrive/insta-reel/sample_vid_data/non-smoking.mp4'\n","pred,prob = predict_smoking_video_1(video_path)\n","pred,prob"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1j00_cwmCp2k","executionInfo":{"status":"ok","timestamp":1714399856858,"user_tz":-330,"elapsed":2944,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"47568191-0adb-413a-c744-68af7c6e1167"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/379 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 102ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 26/379 [00:00<00:02, 152.02it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 94ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 51/379 [00:00<00:02, 152.52it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 94ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 76/379 [00:00<00:01, 154.14it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 95ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 101/379 [00:00<00:01, 153.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 100ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 126/379 [00:00<00:01, 152.71it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 93ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 151/379 [00:00<00:01, 155.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 91ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▋     | 176/379 [00:01<00:01, 154.76it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 89ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 201/379 [00:01<00:01, 156.27it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 92ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 226/379 [00:01<00:00, 157.04it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 99ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 251/379 [00:01<00:00, 155.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 92ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 276/379 [00:01<00:00, 155.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 93ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 301/379 [00:01<00:00, 156.49it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 94ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 326/379 [00:02<00:00, 156.48it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 91ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 351/379 [00:02<00:00, 157.80it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 95ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 379/379 [00:02<00:00, 156.77it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["('not smoking', 0.84)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1312,"status":"ok","timestamp":1714399858166,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"},"user_tz":-330},"id":"pA8kygvS51kF","outputId":"6a2ea0b8-94b0-4c1e-9ce0-09d942e0ec3a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.engine.sequential.Sequential at 0x7c34d85ad840>"]},"metadata":{},"execution_count":15}],"source":["explicit_model_path = '/content/drive/MyDrive/insta-reel/vid_model_checkpoint.keras'\n","explicit_model = tf.keras.models.load_model(explicit_model_path)\n","explicit_model"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"fbl36p929jBQ","executionInfo":{"status":"ok","timestamp":1714399858166,"user_tz":-330,"elapsed":3,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"outputs":[],"source":["# Specify the height and width to which each video frame will be resized in our dataset.\n","IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n","\n","# Specify the number of frames of a video that will be fed to the model as one sequence.\n","SEQUENCE_LENGTH = 20\n","\n","# Specify the list containing the names of the classes used for training. Feel free to choose any set of classes.\n","CLASSES_LIST = ['explicit', 'normal']"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"5BhthGXM90xQ","executionInfo":{"status":"ok","timestamp":1714399858166,"user_tz":-330,"elapsed":3,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"outputs":[],"source":["import cv2\n","def frames_extraction(video_path):\n","    '''\n","    This function will extract the required frames from a video after resizing and normalizing them.\n","    Args:\n","        video_path: The path of the video in the disk, whose frames are to be extracted.\n","    Returns:\n","        frames_list: A list containing the resized and normalized frames of the video.\n","    '''\n","\n","    # Declare a list to store video frames.\n","    frames_list = []\n","\n","    # Read the Video File using the VideoCapture object.\n","    video_reader = cv2.VideoCapture(video_path)\n","\n","    # Get the total number of frames in the video.\n","    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Calculate the the interval after which frames will be added to the list.\n","    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n","\n","    # Iterate through the Video Frames.\n","    for frame_counter in range(SEQUENCE_LENGTH):\n","\n","        # Set the current frame position of the video.\n","        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n","\n","        # Reading the frame from the video.\n","        success, frame = video_reader.read()\n","\n","        # Check if Video frame is not successfully read then break the loop\n","        if not success:\n","            break\n","\n","        # Resize the Frame to fixed height and width.\n","        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n","\n","        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n","        normalized_frame = resized_frame / 255\n","\n","        # Append the normalized frame into the frames list\n","        frames_list.append(normalized_frame)\n","\n","    # Release the VideoCapture object.\n","    video_reader.release()\n","\n","    # Return the frames list.\n","    return frames_list"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"C26BbCqO93JO","executionInfo":{"status":"ok","timestamp":1714399858166,"user_tz":-330,"elapsed":3,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"outputs":[],"source":["def vid_class_pred(path,class_list):\n","    arr = np.array(frames_extraction(path))\n","    arr = np.expand_dims(arr, axis=0)\n","    model_pred = explicit_model.predict(arr).ravel()\n","    pred_prob = max(model_pred)\n","    pred_class = class_list[np.argmax(model_pred)]\n","    return pred_class,round(pred_prob,2)"]},{"cell_type":"code","source":["class_list = CLASSES_LIST\n","path = '/content/drive/MyDrive/insta-reel/sample_vid_data/explicit/SaveInsta.App - 3037680951642907011_1327453630.mp4'\n","pred_class,pred_prob = vid_class_pred(path,class_list)\n","pred_class,pred_prob"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAQexydqEKMn","executionInfo":{"status":"ok","timestamp":1714399860077,"user_tz":-330,"elapsed":1913,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"094d9d4c-8b42-48ee-8a24-c8c45a73d8e3"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 769ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["('explicit', 1.0)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["class_list = CLASSES_LIST\n","path = '/content/drive/MyDrive/insta-reel/sample_vid_data/normal/SaveInsta.App - 3241741895495626070_55489127536.mp4'\n","pred_class,pred_prob = vid_class_pred(path,class_list)\n","pred_class,pred_prob"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tltp2qcEZHA","executionInfo":{"status":"ok","timestamp":1714399861909,"user_tz":-330,"elapsed":1834,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"4e9a3193-a669-4c38-e8f9-e3ddea7356c8"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 57ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["('normal', 0.95)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":21,"metadata":{"id":"RHGbjGmy1jbT","executionInfo":{"status":"ok","timestamp":1714399863075,"user_tz":-330,"elapsed":1167,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"outputs":[],"source":["from moviepy.editor import VideoFileClip\n","\n","# Function to separate audio and save it as MP3\n","def separate_audio(video_path, save_path):\n","    video = VideoFileClip(video_path)\n","    audio = video.audio\n","    if audio is not None:\n","        audio.write_audiofile(save_path)\n","    else:\n","        print(\"No audio track found in the video.\")\n","    video.close()\n","\n","# Function to mute video and save it\n","def mute_video(video_path, save_path):\n","    video = VideoFileClip(video_path)\n","    muted_video = video.set_audio(None)\n","    muted_video.write_videofile(save_path, codec=\"libx264\")\n","    video.close()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jibIGSY1t_I","outputId":"677db1f4-de97-49fd-957c-d7ccf96dad9b","executionInfo":{"status":"ok","timestamp":1714399872472,"user_tz":-330,"elapsed":9398,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["MoviePy - Writing audio in audio/sample_int_vid.mp3\n"]},{"output_type":"stream","name":"stderr","text":["                                                                      "]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Audio separated and saved as audio/sample_int_vid.mp3\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["import os\n","video_name = 'sample_int_vid.mp4'\n","video_path = '/content/drive/MyDrive/insta-reel/sample_vid_data/sample_int_vid.mp4'\n","audio_save_path = os.path.join(\"audio\", video_name.replace(\".mp4\", \".mp3\"))\n","muted_video_save_path = os.path.join(\"muted_videos\", video_name)\n","\n","# Create directories if they don't exist\n","os.makedirs(\"uploads\", exist_ok=True)\n","os.makedirs(\"audio\", exist_ok=True)\n","os.makedirs(\"muted_videos\", exist_ok=True)\n","\n","# Separate audio and save it as MP3\n","separate_audio(video_path, audio_save_path)\n","print(f\"Audio separated and saved as {audio_save_path}\")\n","\n","# Mute the video and save it\n","# mute_video(video_path, muted_video_save_path)\n","# print(f\"Muted video saved as {muted_video_save_path}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9770,"status":"ok","timestamp":1714399882233,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"},"user_tz":-330},"id":"oYDC8KNu0XZf","outputId":"598dfd46-af5e-4cd5-9cbe-e3d6cf88409b"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 181MiB/s]\n"]}],"source":["import whisper\n","model = whisper.load_model(\"base\")\n","\n","def transcribe(audio):\n","\n","    # load audio and pad/trim it to fit 30 seconds\n","    audio = whisper.load_audio(audio)\n","    audio = whisper.pad_or_trim(audio)\n","\n","    # make log-Mel spectrogram and move to the same device as the model\n","    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n","\n","    # detect the spoken language\n","    _, probs = model.detect_language(mel)\n","    print(f\"Detected language: {max(probs, key=probs.get)}\")\n","\n","    # decode the audio\n","    options = whisper.DecodingOptions()\n","    result = whisper.decode(model, mel, options)\n","    return result.text"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"E3lSRaXk0igW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714399983055,"user_tz":-330,"elapsed":100824,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"4b295c4f-7e8a-47d4-eaf9-8740a6083653"},"outputs":[{"output_type":"stream","name":"stdout","text":["Detected language: en\n","I'm Ashley. If you're watching this video, it's a safe bet that you're preparing for a job interview and feel like you need a little help. Your interview is also likely to be virtual, i.e. a remote video call. To get hired in today's job market, it is essential to master the art of the virtual interview.\n"]}],"source":["easy_text = transcribe(\"/content/audio/sample_int_vid.mp3\")\n","print(easy_text)"]},{"cell_type":"code","source":["!pip install gradio\n","!pip install profanity"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMGz54zdWbZP","executionInfo":{"status":"ok","timestamp":1714399998800,"user_tz":-330,"elapsed":15749,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"e6adbddd-8c69-49c5-9726-5fd6690aa14c"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-4.28.3-py3-none-any.whl (12.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.110.2-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.16.0 (from gradio)\n","  Downloading gradio_client-0.16.0-py3-none-any.whl (314 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.4/314.4 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.3.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.0)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart>=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.4.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Collecting typer<1.0,>=0.12 (from gradio)\n","  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.0->gradio) (2024.3.1)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.0->gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.1)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=c02b01f69aa0c60084cb43627e517b063a2d8aa92da9799248872af4fb3188e9\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, httpcore, typer, httpx, fastapi, gradio-client, gradio\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.9.4\n","    Uninstalling typer-0.9.4:\n","      Successfully uninstalled typer-0.9.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.110.2 ffmpy-0.3.2 gradio-4.28.3 gradio-client-0.16.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.1 pydub-0.25.1 python-multipart-0.0.9 ruff-0.4.2 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 uvicorn-0.29.0 websockets-11.0.3\n","Collecting profanity\n","  Downloading profanity-1.1.tar.gz (3.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: profanity\n","  Building wheel for profanity (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for profanity: filename=profanity-1.1-py3-none-any.whl size=4226 sha256=4cea8b7c872630506335894723938a9aab56f8fb3417ceb7471534938ff201e6\n","  Stored in directory: /root/.cache/pip/wheels/2e/05/26/847aedfe1aa25a89f3ed55d4326de446f2b1a7851223c5ca7a\n","Successfully built profanity\n","Installing collected packages: profanity\n","Successfully installed profanity-1.1\n"]}]},{"cell_type":"code","source":["from profanity import profanity\n","profanity_res = profanity.contains_profanity(\"You smell like shit.\")\n","profanity_res"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEJMF8H8eNut","executionInfo":{"status":"ok","timestamp":1714399998801,"user_tz":-330,"elapsed":12,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"cc478dce-683b-4228-e525-43e9a8f2a55e"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["def prediction_on_audio(audio_path):\n","    if not os.path.exists(audio_path):\n","        print(\"No audio file found.\")\n","        return 'no_audio', 0, False\n","\n","    text = transcribe(audio_path)\n","    pred, prob = predict_hate_speech(text)\n","    profanity_res = profanity.contains_profanity(text)\n","    return pred, prob, profanity_res"],"metadata":{"id":"RmyJJRr05f0g","executionInfo":{"status":"ok","timestamp":1714399998801,"user_tz":-330,"elapsed":8,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def respond(video_path):\n","    video_name = os.path.basename(video_path)\n","    audio_save_path = video_name.replace(\".mp4\", \".mp3\")\n","    separate_audio(video_path, audio_save_path)\n","    # muted_video_save_path = video_path\n","    # mute_video(video_path, muted_video_save_path)\n","    pred1,prob1,prof_res = prediction_on_audio(audio_save_path)\n","    hate_speech_pred = f\"Profanity Rating = {prof_res}, Hate speech Pred = {pred1}, Hate speech prob = {prob1} \"\n","\n","    pred2,prob2 = predict_smoking_video_2(video_path)\n","    smoking_pred = f\"Pred = {pred2}, prob = {prob2}\"\n","\n","    class_list = ['explicit', 'normal']\n","    pred3,prob3 = vid_class_pred(video_path,class_list)\n","\n","    explicit_pred = f\"Pred = {pred3}, prob = {prob3}\"\n","\n","    if (pred1 != 'neither') or (pred2 != 'not smoking') or (pred3 != 'normal'):\n","        final_pred = 'detrimental'\n","    else:\n","        final_pred = 'non-detrimental'\n","\n","    final_pred = f\"Pred = {final_pred}\"\n","\n","    return hate_speech_pred,smoking_pred,explicit_pred,final_pred"],"metadata":{"id":"6TDC7X-_KmGi","executionInfo":{"status":"ok","timestamp":1714399998801,"user_tz":-330,"elapsed":8,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["video_path = '/content/drive/MyDrive/insta-reel/sample_vid_data/normal/SaveInsta.App - 3241741895495626070_55489127536.mp4'\n","hate_speech_pred,smoking_pred,explicit_pred,final_pred = respond(video_path)\n","hate_speech_pred,smoking_pred,explicit_pred,final_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h2oLsa3xKn9y","executionInfo":{"status":"ok","timestamp":1714400125142,"user_tz":-330,"elapsed":126348,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"88e9c994-b1d4-47e0-acf1-5b2ca8c604f5"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["MoviePy - Writing audio in SaveInsta.App - 3241741895495626070_55489127536.mp3\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Detected language: en\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 99ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 1/20 [00:00<00:04,  4.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 93ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 2/20 [00:00<00:06,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 98ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 3/20 [00:01<00:06,  2.48it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 97ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 4/20 [00:01<00:07,  2.12it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 93ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 5/20 [00:02<00:07,  1.89it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 100ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 6/20 [00:02<00:07,  1.76it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 101ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 7/20 [00:03<00:08,  1.62it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 104ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 8/20 [00:04<00:08,  1.48it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 91ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 9/20 [00:05<00:07,  1.39it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 95ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 10/20 [00:06<00:07,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 95ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 11/20 [00:07<00:07,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 96ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 12/20 [00:08<00:07,  1.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 94ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 13/20 [00:09<00:06,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 92ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 14/20 [00:10<00:06,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 94ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 15/20 [00:11<00:05,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 90ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 16/20 [00:11<00:03,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 97ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 17/20 [00:12<00:02,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 95ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 18/20 [00:13<00:01,  1.34it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 89ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 19/20 [00:13<00:00,  1.31it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 95ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:28<00:00,  1.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 66ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["('Profanity Rating = False, Hate speech Pred = offensive_language, Hate speech prob = 0.41 ',\n"," 'Pred = not smoking, prob = 0.6899999976158142',\n"," 'Pred = normal, prob = 0.949999988079071',\n"," 'Pred = detrimental')"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["import gradio as gr\n","import os\n","\n","with gr.Blocks(theme=gr.themes.Soft()) as demo:\n","    gr.Markdown(\n","        \"\"\"\n","        # Video Content Moderation Model Demo WebApp\n","        Detects obscene, smoking, hate speech content in a given video\n","        \"\"\")\n","\n","    hate_speech_pred = gr.Textbox(label=\"hate_speech_pred\")\n","    smoking_pred = gr.Textbox(label=\"smoking_pred\")\n","    explicit_pred = gr.Textbox(label=\"explicit_pred\")\n","    final_pred = gr.Textbox(label=\"final_pred\")\n","    input_video = gr.Video(sources=[\"upload\",\"webcam\"],label=\"input_video\")\n","    submit_btn = gr.Button(value='submit')\n","    clear = gr.ClearButton([hate_speech_pred,smoking_pred,explicit_pred,final_pred,input_video])\n","\n","    def respond(video_path):\n","      video_name = os.path.basename(video_path)\n","      audio_save_path = video_name.replace(\".mp4\", \".mp3\")\n","      separate_audio(video_path, audio_save_path)\n","      # muted_video_save_path = video_path\n","      # mute_video(video_path, muted_video_save_path)\n","      pred1,prob1,prof_res = prediction_on_audio(audio_save_path)\n","      hate_speech_pred = f\"Profanity Rating = {prof_res}, Hate speech Pred = {pred1}, Hate speech prob = {prob1} \"\n","\n","      pred2,prob2 = predict_smoking_video_2(video_path)\n","      smoking_pred = f\"Pred = {pred2}, prob = {prob2}\"\n","\n","      class_list = ['explicit', 'normal']\n","      pred3,prob3 = vid_class_pred(video_path,class_list)\n","\n","      explicit_pred = f\"Pred = {pred3}, prob = {prob3}\"\n","\n","      if (pred1 != 'neither') or (pred2 != 'not smoking') or (pred3 != 'normal'):\n","          final_pred = 'detrimental'\n","      else:\n","          final_pred = 'non-detrimental'\n","\n","      final_pred = f\"Pred = {final_pred}\"\n","\n","      return hate_speech_pred,smoking_pred,explicit_pred,final_pred\n","\n","    submit_btn.click(respond, [input_video], [hate_speech_pred,smoking_pred,explicit_pred,final_pred])\n","\n","demo.launch(debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":799},"id":"w51S7EqYDXVa","executionInfo":{"status":"ok","timestamp":1714403808424,"user_tz":-330,"elapsed":3555692,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}},"outputId":"9aa93862-4cfa-4085-c785-e8a972d108e2"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://0b2c2bf16ffeb8b95c.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://0b2c2bf16ffeb8b95c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["MoviePy - Writing audio in How to light a cigarette in style.mp3\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Detected language: en\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 104ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 1/20 [00:00<00:03,  5.39it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 92ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 2/20 [00:00<00:03,  4.53it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 90ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 2/20 [00:00<00:06,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 53ms/step\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://0b2c2bf16ffeb8b95c.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[],"metadata":{"id":"FHpc6LYjKPwi","executionInfo":{"status":"ok","timestamp":1714400237451,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0R5Yj2xzKPzE","executionInfo":{"status":"ok","timestamp":1714400237451,"user_tz":-330,"elapsed":4,"user":{"displayName":"Harriesh R A","userId":"00017023247568434653"}}},"execution_count":30,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}